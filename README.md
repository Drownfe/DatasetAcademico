
# ğŸ“ PredicciÃ³n AcadÃ©mica â€” Notas y CrÃ©ditos (VersiÃ³n Avanzada)

AplicaciÃ³n web **Flask + scikit-learn + Chart.js** para **regresiÃ³n acadÃ©mica** con datasets grandes.  
Compara varios modelos, ejecuta **validaciÃ³n cruzada**, calcula **mÃ©tricas avanzadas** y muestra **grÃ¡ficas** interactivas.  
Incluye **descargas** del dataset y resultados.

---

## ğŸš€ Novedades de esta versiÃ³n

- **Dataset grande y paramÃ©trico**: genera 10k, 15k, 20k+ filas realistas (selector en la UI).
- **Re-creaciÃ³n bajo demanda**: casilla *Re-crear dataset* para regenerar con el tamaÃ±o elegido.
- **MÃ¡s mÃ©tricas**: `MAE`, `RMSE`, `MAPE%`, `RÂ²` y baseline por promedio.
- **ValidaciÃ³n cruzada (K-Fold, k=5)**: reporte `media Â± desviaciÃ³n` para `RÂ²` y `MAE`.
- **ComparaciÃ³n de modelos**: `LinearRegression`, `Ridge`, `Lasso`, `RandomForest`, `GradientBoosting`.
- **GrÃ¡ficas nuevas**:
  - **Barras**: RÂ² por modelo (comparaciÃ³n).
  - **Barras**: Importancia de variables o coeficientes del mejor modelo.
  - **DispersiÃ³n**: Real vs. Predicho (con miles de puntos muestreados).
  - **Histograma**: DistribuciÃ³n de residuales.
  - **Heatmap**: Matriz de correlaciÃ³n entre X y Y (tabla coloreada).
- **Descargas**: botones para **CSV** del dataset y **JSON** con todos los resultados.

---

## ğŸ“¦ Dataset

Se genera de forma **sintÃ©tica pero realista** con estas columnas:

**Entradas (X):**
- `PromedioAcumulado` (0â€“5)
- `AsistenciaPct` (50â€“100%)
- `HorasEstudioSem` (0â€“25 h)
- `TareasEntregadasPct` (30â€“100%)
- `Parcial1`, `Parcial2` (1â€“5)
- `DificultadMateria` (1â€“5)
- `IntentosReprobados` (0â€“2)

**Salidas (Y):**
- `NotaFinal` (0â€“5) â€” *objetivo de la regresiÃ³n*
- `CreditosAsignados` â€” determinada por polÃ­tica segÃºn `PromedioAcumulado`

> La **NotaFinal** se construye con una fÃ³rmula ponderada + ruido + penalizaciones por dificultad e intentos previos.

---

## ğŸ§  Modelos y MÃ©tricas

Modelos evaluados automÃ¡ticamente:
- `LinearRegression`
- `Ridge (Î±=1.0)`
- `Lasso (Î±=0.01)`
- `RandomForestRegressor (n_estimators=200)`
- `GradientBoostingRegressor`

MÃ©tricas reportadas por modelo (holdout 80/20):
- **MAE** (error absoluto medio)
- **RMSE** (raÃ­z del MSE)
- **MAPE%** (error porcentual absoluto medio)
- **RÂ²** (explicaciÃ³n de la varianza)

Adicionalmente, se calcula:
- **Baseline** (predecir el promedio de `NotaFinal`) para comparar.
- **K-Fold CV (k=5)**: `RÂ²` y `MAE` con **media Â± desviaciÃ³n estÃ¡ndar**.

---

## ğŸ“Š Visualizaciones

1. **ComparaciÃ³n de modelos (RÂ²)** â€” *Barras.*  
   Muestra quÃ© modelo generaliza mejor (mÃ¡s alto es mejor).
2. **Importancia/Coeficientes (mejor modelo)** â€” *Barras.*  
   - Si el mejor modelo es no lineal (p. ej., RandomForest), muestra `feature_importances_`.
   - Si es lineal (p. ej., Ridge), muestra los **coeficientes**.
3. **Real vs. Predicho** â€” *DispersiÃ³n.*  
   Nube de puntos con muestra de hasta 1500 observaciones; idealmente cerca de la lÃ­nea `y = x`.
4. **DistribuciÃ³n de residuales** â€” *Histograma.*  
   Permite ver si los errores se concentran alrededor de 0 (buena seÃ±al).
5. **Matriz de correlaciÃ³n** â€” *Heatmap (tabla coloreada).*  
   Observa relaciones entre todas las variables X y Y (positivo en azul, negativo en rojo).
6. **Vistas previas X / Y** â€” *Tablas.*  
   Primeras filas de **entradas** (X) y **salidas** (Y).

---

## ğŸŒ Endpoints y Descargas

- **App**: `GET /`  
  UI con selector de tamaÃ±o, botÃ³n para correr el pipeline y visualizaciones.
- **Iniciar pipeline**: `GET /start?n=10000&force=0|1`  
  - `n`: tamaÃ±o solicitado del dataset.
  - `force=1`: regenera el CSV, aunque exista.
- **Descargar dataset**: `GET /download/dataset?n=10000&force=0|1` â†’ `dataset_notas.csv`
- **Descargar resultados**: `GET /download/results?n=10000&force=0|1` â†’ `resultados.json`

> Los enlaces de descarga tambiÃ©n estÃ¡n disponibles como botones en la interfaz.

---

## ğŸ’» InstalaciÃ³n y ejecuciÃ³n

```bash
python -m venv venv
# Windows
venv\Scripts\activate
# macOS/Linux
source venv/bin/activate

pip install --upgrade pip setuptools wheel
pip install -r requirements.txt

python app.py
```

Abrir **http://127.0.0.1:5000**.  
Elegir tamaÃ±o (*10k por defecto*), marcar **Re-crear** si se desea regenerar, y pulsar **â–¶ï¸ Empezar**.

---

## ğŸ§© CÃ³mo leer los resultados

- **Baseline**: sirve de referencia mÃ­nima; cualquier modelo Ãºtil debe superarlo.
- **ComparaciÃ³n (RÂ²)**: elige el modelo con RÂ² mÃ¡s alto sin sacrificar mucho MAE/MAPE.
- **Importancia**: identifica quÃ© variables pesan mÃ¡s en la predicciÃ³n (Ãºtil para recomendaciones).
- **Real vs. Predicho**: puntos cercanos a la diagonal indican buena precisiÃ³n.
- **Residuales**: distribuciÃ³n centrada en 0 y relativamente estrecha = mejor ajuste.
- **Correlaciones**: verifica relaciones lineales fuertes y multicolinealidad potencial.

---

## ğŸ“ Estructura del proyecto

```
tu_carpeta/
â”œâ”€ app.py                # Backend (Flask + scikit-learn)
â”œâ”€ requirements.txt      # Dependencias
â”œâ”€ templates/
â”‚  â””â”€ index.html         # UI principal + contenedores de grÃ¡ficos
â””â”€ static/
   â”œâ”€ style.css          # Estilos
   â””â”€ app.js             # LÃ³gica de front + Chart.js
```

---

## ğŸ Autor

**Juan Felipe HernÃ¡ndez Palacio (Drownfe)**  
Proyecto acadÃ©mico â€” *PredicciÃ³n de Nota Final y CrÃ©ditos con ML*.
